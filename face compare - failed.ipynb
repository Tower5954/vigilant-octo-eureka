{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-476a26263085>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-476a26263085>\"\u001b[0;36m, line \u001b[0;32m73\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#built with https://pbpython.com/python-face-detect.html isnt the best so trying again\n",
    "\n",
    "\n",
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, SnapshotObjectType, OperationStatusType\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def annotate_image(labeled_image, response_data = annotate_image(\n",
    "    \"David Mitchell01.jpg\",subscription_key)):\n",
    "#    Helper function for Microsoft Azure face detector.\n",
    "\n",
    "#     Args:\n",
    "#         image_url: Can be a remote http://  or file:// url pointing to an image less then 10MB\n",
    "#         subscription_key: Cognitive services generated key\n",
    "#         api_url: API end point from Cognitive services\n",
    "#         show_face_id: If True, display the first 6 characters of the faceID\n",
    "\n",
    "#     Returns:\n",
    "#         figure: matplotlib figure that contains the image and boxes around the faces with their age and gender\n",
    "#         json response: Full json data returned from the API call\n",
    "\n",
    "#     \n",
    "\n",
    "    subscription_key = 'f9ffacac18804f35a6c9fc7e02ac5589'\n",
    "face_api_url = 'https://towvis-fennac.cognitiveservices.azure.com/face/v1.0/detect'\n",
    "face_api_url_verify = 'https://towvis-fennac.cognitiveservices.azure.com/face/v1.0/verify'\n",
    "api_url = 'https://towvis-fennac.cognitiveservices.azure.com'\n",
    "\n",
    " # The default header must include the sunbscription key\n",
    "headers = {'Ocp-Apim-Subscription-Key': subscription_key}\n",
    "\n",
    "params = {\n",
    "        'returnFaceId': 'true',\n",
    "        'returnFaceLandmarks': 'false',\n",
    "        'returnFaceAttributes': 'age,gender,headPose,smile,facialHair,glasses,emotion,hair,makeup,occlusion,accessories,blur,exposure,noise',\n",
    "    }\n",
    "\n",
    "# Figure out if this is a local file or url\n",
    "parsed_url = urlparse(image_url)\n",
    "if parsed_url.scheme == 'file':\n",
    "    image_data = open(parsed_url.path,\"rb\").read()\n",
    "\n",
    "# When making the request, we need to add a Content-Type Header\n",
    "# and pass data instead of a url\n",
    "headers['Content-Type']='application/octet-stream'\n",
    "response = requests.post(api_url, params=params, headers=headers)\n",
    "\n",
    "# Open up the image for plotting\n",
    "image = Image.open(parsed_url.path)\n",
    "\n",
    "# Pass in the URL to the API\n",
    "else:\n",
    "response = requests.post(api_url, params=params, headers=headers, json={\"url\": image_url})\n",
    "image_file = BytesIO(requests.get(image_url).content)\n",
    "image = Image.open(image_file)\n",
    "\n",
    "faces = response.json()\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(image, alpha=0.6)\n",
    "\n",
    "for face in faces:\n",
    "    fr = face[\"faceRectangle\"]\n",
    "    fa = face[\"faceAttributes\"]\n",
    "    origin = (fr[\"left\"], fr[\"top\"])\n",
    "    p = patches.Rectangle(origin, fr[\"width\"],\n",
    "    fr[\"height\"], fill=False, linewidth=2, color='b')\n",
    "    ax.axes.add_patch(p)\n",
    "    ax.text(origin[0], origin[1], \"%s, %d\"%(fa[\"gender\"].capitalize(), fa[\"age\"]),\n",
    "    fontsize=16, weight=\"bold\", va=\"bottom\")\n",
    "\n",
    "if show_face_id:\n",
    "    ax.text(origin[0], origin[1]+fr[\"height\"], \"%s\"%(face[\"faceId\"][:5]),\n",
    "    fontsize=12, va=\"bottom\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    # Explicitly closing image so it does not show in the notebook\n",
    "    plt.close()\n",
    "    return fig, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
